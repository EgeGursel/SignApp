{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fd70ddf",
   "metadata": {},
   "source": [
    "# 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "526c9d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: tensorflow-gpu in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.8.10.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.23.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.47.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (21.4.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (4.6.0.66)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sklearn) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.34.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.9.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\gurse\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow-gpu opencv-python mediapipe sklearn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b0c928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f6e514",
   "metadata": {},
   "source": [
    "# 2. Keypoints using MP Holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb08a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe holistic model\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# MediaPipe drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9b746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp_detection(image, model):\n",
    "    \n",
    "    # Color conversion - BGR to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Make the image unwriteable to save bandwith\n",
    "    image.flags.writeable = False\n",
    "    \n",
    "    # Make prediction\n",
    "    results = model.process(image)\n",
    "    \n",
    "    # Image is now writeable again (next frame)\n",
    "    image.flags.writeable = True\n",
    "    \n",
    "    # Color conversion - RGB to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2724029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mp_draw_landmarks(image, results):\n",
    "    \n",
    "    # Draw the hand and pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                             mp_drawing.DrawingSpec(color=(80, 110, 10), thickness = 1, circle_radius = 1),\n",
    "                             mp_drawing.DrawingSpec(color=(80, 256, 120), thickness = 1, circle_radius = 1))\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f50f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access webcam\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Set MediaPipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as holistic:\n",
    "    \n",
    "    # While the webcam is open\n",
    "    while capture.isOpened():\n",
    "        \n",
    "        # Read the webcam feed\n",
    "        ret, frame = capture.read()\n",
    "        \n",
    "        # Make detections\n",
    "        image, results = mp_detection(frame, holistic)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        mp_draw_landmarks(image, results)\n",
    "        \n",
    "        # Show the webcam feed to the window\n",
    "        cv2.imshow(\"OpenCV Video Feed\", image)\n",
    "        \n",
    "        # Break the loop when q is pressed\n",
    "        if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # Stop the webcam feed\n",
    "    capture.release()\n",
    "    \n",
    "    # Close the webcam window\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809ec917",
   "metadata": {},
   "source": [
    "# 3. Extract Keypoint Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b43043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    \n",
    "    # If there is data collected for the face, hands, and pose; extract the keypoint values\n",
    "    if results.face_landmarks:\n",
    "        face = np.array([[i.x, i.y, i.z] for i in results.pose_landmarks.landmark]).flatten()\n",
    "    else:\n",
    "        face = np.zeros(468*3)\n",
    "        \n",
    "    if results.right_hand_landmarks:\n",
    "        rh = np.array([[i.x, i.y, i.z] for i in results.right_hand_landmarks.landmark]).flatten()\n",
    "    else:\n",
    "        rh = np.zeros(21*3)\n",
    "\n",
    "    if results.left_hand_landmarks:\n",
    "        lh = np.array([[i.x, i.y, i.z] for i in results.left_hand_landmarks.landmark]).flatten()\n",
    "    else:\n",
    "        lh = np.zeros(21*3)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        pose = np.array([[i.x, i.y, i.z, i.visibility] for i in results.pose_landmarks.landmark]).flatten()\n",
    "    else:\n",
    "        pose = np.zeros(33*4)\n",
    "        \n",
    "    return np.concatenate([face, rh, lh, pose])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007a25e8",
   "metadata": {},
   "source": [
    "# 4. Setup Folders for Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7346cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join(\"MP_Data\")\n",
    "\n",
    "# Signs to detect\n",
    "actions = np.array([\"hello\"])\n",
    "\n",
    "# Number of videos\n",
    "videos = 30\n",
    "\n",
    "# Videos are 30 frames in length\n",
    "video_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "308bf8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for data collection\n",
    "for i in actions:\n",
    "    for j in range(videos):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH, i, str(j)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2820dd43",
   "metadata": {},
   "source": [
    "# 5. Collect Keypoint Values for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "debfadc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, video no. \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(action, video \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), (\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m20\u001b[39m),\n\u001b[0;32m     32\u001b[0m                 cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.6\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m1\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mLINE_AA)\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Break between each video\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, video no. \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(action, video \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), (\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m20\u001b[39m),\n\u001b[0;32m     38\u001b[0m                 cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.6\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m1\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mLINE_AA)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Access webcam\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Set MediaPipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "    # While the webcam is open\n",
    "    while capture.isOpened():\n",
    "\n",
    "        # Loop through each action\n",
    "        for action in actions:\n",
    "            # Loop through each video of action\n",
    "            for video in range(videos):\n",
    "                # Loop through each frame of video\n",
    "                for video_frame in range(video_length):\n",
    "\n",
    "                    # Read the webcam feed\n",
    "                    ret, frame = capture.read()\n",
    "\n",
    "                    # Make detections\n",
    "                    image, results = mp_detection(frame, holistic)\n",
    "\n",
    "                    # Draw landmarks\n",
    "                    mp_draw_landmarks(image, results)\n",
    "\n",
    "                    # Collect each frame\n",
    "                    if video_frame == 0:\n",
    "                        # Informative text on screen\n",
    "                        cv2.putText(image, \"STARTING COLLECTION\", (120, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0),\n",
    "                                    4, cv2.LINE_AA)\n",
    "                        cv2.putText(image, \"Data for '{}', video no. {}\".format(action, video + 1), (20, 20),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "                        # Break between each video\n",
    "                        cv2.waitKey(1500)\n",
    "                    else:\n",
    "                        cv2.putText(image, \"Data for '{}', video no. {}\".format(action, video + 1), (20, 20),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "                    # Export keypoint data to its designated directory\n",
    "                    keypoints = extract_keypoints(results)\n",
    "                    npy_path = os.path.join(DATA_PATH, action, str(video), str(video_frame))\n",
    "                    np.save(npy_path, keypoints)\n",
    "\n",
    "                    # Show the webcam feed to the window\n",
    "                    cv2.imshow(\"OpenCV Video Feed\", image)\n",
    "\n",
    "                    # Break the loop when q is pressed\n",
    "                    if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "                        # Stop the webcam feed\n",
    "                        capture.release()\n",
    "                        # Close the webcam window\n",
    "                        cv2.destroyAllWindows()\n",
    "\n",
    "    # Stop the webcam feed\n",
    "    capture.release()\n",
    "    # Close the webcam window\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13311690",
   "metadata": {},
   "source": [
    "# 6. Preprocess Data and Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9097f8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
